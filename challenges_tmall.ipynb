{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping using Python - Try it yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the necessary libraries and parsing the very first page of one of the products (e.g. a notebook for taking notes üìì) on [TMall](https://list.tmall.com/search_product.htm?q=%B1%BE%D7%D3&type=p&vmarket=&spm=875.7931836%2FB.a2227oh.d100&xl=ben_1&from=mallfp..pc_1_suggest) website.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every paragraph in this document is a cell, that can contain other text description, or a snippet of runnable Python code.\n",
    "\n",
    "To run the cell, select it and click \"Run\" in the toolbar, or just press Shift-Enter. Double-clicking the cell allows you to edit its contents.\n",
    "\n",
    "**Pro tip ü§ì:** Run your cells often to catch possible errors early!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "item = \"\" #type a product that you want to search between quotes (e.g. \"notebook\" or \"Êú¨Â≠ê\")\n",
    "url = f\"https://list.tmall.com/search_product.htm?q={item}\" # here we use 'literal string interpolation' to input our item\n",
    "response = requests.get(url)\n",
    "html = response.content\n",
    "scraped = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After **running** a cell above, you'll be able to use the `scraped` variable to look for elements on the page.\n",
    "\n",
    "In order to see the page that we just run `scraped`, run a cell below. üë©‚Äçüíª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraped "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Print the title of the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print output in Python, you can use the `print()` function. It can either take a literal value as an argument`(print(\"hello\")`, `print(2))`, or a variable - in that case function will print the value that the variable refers to!\n",
    "\n",
    "```python\n",
    "name = \"Bob\"\n",
    "print(name) # => Bob\n",
    "```\n",
    "\n",
    "Remember you need to print just **text** inside the `<title>` tag, not the whole element!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <strong>Reveal answer ü§´</strong>\n",
    "</summary>\n",
    "<pre>\n",
    "page_title = scraped.title.text\n",
    "print(page_title)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Print a *price* of the first product on the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how to locate a single element with BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <strong>Reveal answer ü§´</strong>\n",
    "</summary>\n",
    "<pre>\n",
    "first_price = scraped.em.text\n",
    "print(first_price)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Print *all* prices from the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the BeautifulSoup methods that return a *collection* of elements. Remind yourself of how to **loop** over them(`for.. in..` constuct)\n",
    "```python\n",
    "for duck in ducks:\n",
    "    print(duck)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how you can get rid of a currency symbol and convert text to a numerical value(given that the initial text value is in a variable called `price`):\n",
    "\n",
    "`price = float(price.text.lstrip(\"¬•\"))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <strong>Reveal answer ü§´</strong>\n",
    "</summary>\n",
    "<pre>\n",
    "prices = scraped.find_all(\"em\", title=True)\n",
    "for price in prices:\n",
    "    price_float = float(price.text.lstrip(\"¬•\"))\n",
    "    print(price_float)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4: Print a title of the first product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <strong>Reveal answer ü§´</strong>\n",
    "</summary>\n",
    "<pre>\n",
    "first_title = scraped.find('p', class_ = 'productTitle').a['title']\n",
    "print(first_title)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 5: Print *all* titles from the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same operation that we did with prices.\n",
    "\n",
    "**Pro tip ü§ì:** Don't blindly copy-paste code from the cell above. (some corrections needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <strong>Reveal answer ü§´</strong>\n",
    "</summary>\n",
    "<pre>\n",
    "titles = scraped.find_all('p', class_ = 'productTitle')\n",
    "for title in titles:\n",
    "    print(title.a['title'])\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 6: Get a corresponding price for each title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the resulting data structure should look like (a List of Dictionaries):\n",
    "```    \n",
    "[{'ÂæóÂäõÁ¨îËÆ∞Êú¨Â≠êb5ËÆ∞‰∫ãÊú¨ÂéöÊú¨Â≠ê...': 15.8 }, \n",
    "{'Áéõ‰∏ΩÂ∞èÂ≠¶Áîü‰Ωú‰∏öÊú¨ÊâπÂèëÂ∞èÂ≠óÊú¨...': 12.8 }, \n",
    "{'Êô®ÂÖâÁî∞Â≠óÊ†ºÁªÉÂ≠óÊú¨‰Ωú‰∏öÊú¨...': 13.8 }, \n",
    "...]\n",
    "```    \n",
    "Note that the real descriptions will be much longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reminder on how you can append a Dictionary into an List:\n",
    "\n",
    "```python\n",
    "title_prices = []\n",
    "\n",
    "# Iterate over all articles \n",
    "    # Get article's title as `title` \n",
    "    # Get article's price as `price`\n",
    "    title_prices.append({title: price})\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "title_prices = []\n",
    "\n",
    "# write your code here\n",
    "\n",
    "for t_p in title_prices:\n",
    "    print(t_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "<strong>Reveal answer ü§´</strong>\n",
    "</summary>\n",
    "<pre>\n",
    "title_prices = []\n",
    "\n",
    "products = scraped.select(\".product\")\n",
    "\n",
    "for product in products:\n",
    "    title = product.find('p', class_ = 'productTitle').a['title']\n",
    "    price = product.em.text\n",
    "    price_float = float(price.lstrip(\"¬•\"))\n",
    "    title_prices.append({title: price_float}) # Create a Dictionary and append to Array\n",
    "\n",
    "print(title_prices)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above and beyond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can click on \"Save to browser storage\" icon next to \"Download\" on top of this notebook. Next time you connect to MyBinder you can restore your work by clicking \"Restore from browser storage\". \n",
    "\n",
    "Take as much time as you need to build a scraper for any website that you want! Keep in mind the information you are trying to scrape should be in public access and not protected by login/password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for a complete scraper when you feel like it :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
